\documentclass[12pt, a4paper]{scrartcl}

\usepackage{fullpage}

\author{Richard Polzin}
\title{Robot Soccer Localization in 2016}
\subtitle{image-based Localization Techniques in RoboCup Standard Platform League}
\date{\today}

\begin{document}
  \maketitle

  \begin{abstract}
    \textbf{Abstract.}
  \end{abstract}

  \section{Introduction}
  'By the middle of the 21st century, a team of fully autonomous humanoid robot soccer players shall win a soccer game, complying with the official rules of FIFA, against the winner of the most recent World Cup.[]'. This is the official goal of the RoboCup initiative, an international scientific initiative which has several leagues and competition domains wherein robotic teams compete. In addition to competition against other teams, the physical setting of the challenges become more and more realistic year to year. Autonomous, programmable, humanoid robots called 'Nao' are used in the RoboCup Standard Platform League (SPL). A Nao V5 robot has a height of 58 cm and weighs 4.3 kg. It features an 1.6 GHz Intel Atom processor and 1 GB of RAM. The two legged robot is equipped with multiple sensors, as well as wifi, ethernet, and usb interfaces.

  In an attempt to make the environment of the game more realistic, the characteristics of the soccer field are changed regulary. For example, as in the 2008 RoboCup, navigation beacons were used to flag points of interest on the field. Furthermore, the field is no longer surrounded by walls and its size was increased to 60cm by 90cm. In the 2015 tournament, the goals were made color-neutral, whereas previously it was possible to differentiate goals by color.

  As the RoboCup competitors constanly try to keep up with the increasing difficulty of the game, different localization techniques have been investigated and researched. Localization refers to the task of autonomously tracking and maintaining an estimate of a robots location. It is critical for the robots to combine location estimation techniques to acertain a workable estimate. Some robots rely on ultrasonic sensors or lasers, and still others work with an electrical compass. The Nao robots include ultrasonic sensors as well as cameras. This paper will focus on image-based techniques.

  In first section of this paper [] the importance of image-based localization is emphasized. Furthermore the concept of those techniques is explained. The second section [] shows the obstacles that have to be overcome to provide a good localization. Section [] describes the techniques used by different Nao teams and explains the important features of their approaches. Finally in section [] the techniques are compared and common features and differences are evaluated.

  \section{Image-based Localization}
  In a game of soccer, where the robots need to react and collaborate quickly, localization is vital. Passing the ball, positioning, and dribbling all require fast and accurate localization. Localization can be split into local and global localization. Local localization focuses on objects distances relative to the robot. Questions arise and must be answered in very near real time. How far away are other players, goals, and walls? What is the distance to the wall? Answering these questions is integral to good play. On the other hand, global localization comes into play when a robot has to be removed from the field or is replaced. Maintaining the global position on the field allows for better positioning and general orientation, especially with the color coding of the goals removed. For high-quality play, it is important to keep track of the sites of the field. Having great dribbling and shooting many goals is not sufficient if the robot mixes up the enemy goal and its own.

  Localization of the Nao robot is only possible with the sensors it provides. It offers microphones, tactile sensors, bumbers, four sonar sensors, and two cameras. Neither microphones, tactile sensors, nor bumpers are valuable to detect objects far away. Only the camera and sonar sensors can be used. The sonar sensors are divided in two receiving and two emitting devices. Detection was initially possible in the range 20 cm to 80 cm, but with the V4 Version of the Nao, detection range increased to 20 cm to 2.55 m. The camera sensors are positioned in the head and provide an image with 1280 x 960 pixels at 30 frames per second []. Images [] show the orientation of the cameras, while the sonar sensors can certainly be used for collision avoidance and player / ball detection, the camera sensors are more often used for localization. This paper, as well as the different techniques explained later on, will not use the sonar senors, but only work with the cameras.

  After concluding that localization is important, and that cameras are the most promising sensors to use, the concept of image-based localization is explained. A good self-localization should be fast and reliable. Localization needs to run fast enough to react quickly to changes during play and still leave enoungh computational power for the other important algorithms. Furthermore, there should always be an solid estimate of the robots position and should be able to overcome the challenges described in detail in the next section. In general, such a localization process consists of three steps. First an image is recorded and some arbitrary feature is detected. For example the image is scanned for the rectangle of a goal. The second step creates an abstract model of the detected feature. A goal is perceived no longer as a flat rectangle, but as an 3D object. 3D position is determined, and the distance to the robot is calculated. In the final step the robots local map is positioned into the coordinate system of the whole soccer field. Based on the current vision of the robot and its distance to the goal the robots position on the soccer field is determined. The three steps must be individually well-executed and collectively accurate to achieve an optimal localization. Most papers published in the field of RoboCup SPL localization present techniques including all three steps, and adjust them according to a given strategy. Due to the limited scope of this paper, the comparison of techniques will focus on the first step: the extraction of physical geometric features from the image.

  \section{Challenges}
  Image-based localization in RoboCup SPL has to overcome several obstacles that are important in more practical robot applications as well. While the robots sensors are gradually improving year to year, the challenges they face increase as a increasing rate. Similar to human vision, the cameras on the Nao robots offer only a limited field of view. They have to move their heads to fully assess their environment and can't rely on powerful omnidirectional sensors. The cameras have to deal with different lighting conditions. While initially high-quality light was required by the rules, nowadays the game isn't interrupted, even when lightbulbs break down. Additionally, the earlier mentioned color codings were removed. Finally, photographers are now allowed to freely use flash.

  All these different aspects can lead to low quality pictures from the cameras. However, environmental factors are not alone in restricting image uptake quality. While shooting in RAW with a high-quality DSLR and post-processing the image would produce much better results, hardware shall not be changed, and thus hardware limitations must be considered. The 1.6 GHz of the Atom processor and the 1 GB of RAM are all the resources available. Computations still have to be executed as near to real-time as possible. Even ignoring image quality, there are still further challanges to face when it comes to localization. Robots can stand in each others way and occlude the field of view. Relying on color is dangerous as well, as the environment could become more noisy in the future. As the RoboCup initiative aims to win an official FIFA game with colorful advertisements, noisy chanting, and dramatic lighting, these challenges must be predicted and mitigated in localization implementations.

  In conclusion, there are many and varied challenges facing image-based localization which must be addressed to if the ultimate goal of beating a world-class human soccer team is to be achieved.

  \section{Overview of Techniques}
  Images [] show everything that defines the 2015 RoboCub SPL soccer field. It's a mostly-white field with lines and goals on a green carpet. The goal posts and crossbar are white, while the net and support structure can be white, gray or black. Lighting can only come from the ceiling and any changes in the lighting will not be cause for delay. Fields can be in visible range of one another, but if they are they must be at least three meters apart.

  To offer information on current and successful techniques, the work of the best three teams of the RoboCup 2016 in Leipzig, Germany will be considered. The winning teams are B-Human, UT Austin Villa and Nao-Team HTWK, in descending order. In the description for RoboCup 2016, each of these teams will share their publications since RoboCup 2015.

  The B-Human RoboCup team was founded in 2006 and started participating in the SPL in 2009. They competet in seven RoboCups and became world champion four times. Their code is available on GitHub with the intention of nurturing the scientific community and allowing teams who can't afford to develop a complete robot soccer system to participate. For localization the B-Human team uses 'field lines, their crossings, and the center circle' []. In 2015 they added support for penalty area detection. Those features are detected on an image, which in then used to conclude the robots possible positions. B-Human calls those features 'field features'. They include the features mentioned above and the goal frame on the floor. Field lines are detected by collecting all regions that are 'line shaped'. Those are regions that are white and border on green regions. In the next step a greedy algorithm enlarges a line 
  The goal is detected by searching for white regions directly below the field borders. Robots and goal posts are the only objects that can be present on the field. Rules clearly define the size of a goal, so the Sobel operator is used to create an image emphasizing the edges. A Hough transform is then used to detect lines and possible goal lines are fitted onto a model of the goal to validate the hypothesis.



  \section{Conclusion}


\end{document}
